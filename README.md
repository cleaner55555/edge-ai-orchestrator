# edge-ai-orchestrator
ğŸ¦ Distributed Edge AI Orchestrator by Silbaski Dejan - 40x faster, $5 VPS. Local inference + P2P swarm. Democratizing AI for every developer.


## ğŸš€ What is this?

**NOT using existing LLMs** - We build custom fine-tuned 2B specialist models!

- âŒ NOT calling GPT-4/Claude API
- âœ… Building 28+ specialized 2B models
- âœ… Rust orchestrator + local inference
- âœ… 40x faster, 1000x cheaper

## ğŸ¯ Key Innovation

**Custom Fine-Tuned Models** for every task:
- rust-mcp-fixer-2b
- wp-bricks-builder-2b  
- shopify-woo-architect-2b
- ...28 total

Each: 2B params, ~1GB, 20-100 t/s

## ğŸ“Š Performance
**Built with Rust** - Pure Rust inference engine for maximum speed and safety:

- ğŸ¦€ llama.cpp Rust bindings (llama_cpp-rs)
- ğŸ”¥ Candle by Hugging Face (pure Rust ML framework)
- âš¡ mistral.rs (native Rust inference)
- - ğŸ¦™ Ollama integration (Go + llama.cpp backend)
- ğŸš€ Zero Python overheadvs OpenAI API:
- 40x faster (local)
- 1000x cheaper ($0 vs $0.15/1M)
- 100% private

## ğŸ› ï¸ Training

- Base: Qwen2.5-2B- Fine-tune: LoRA on 10k+ examples  
- Quantize: 4-bit
- Cost: $50-100 per model

- ## ğŸ”’ Privacy & Transparency

**Built-in Network Monitoring** - Users can verify LLM behavior in real-time:

- ğŸ“Š Real-time download/upload metrics
- ğŸŒ All outbound connections visible
- ğŸ” Traffic analysis dashboard
- âœ… Zero external data transmission
- ğŸ›¡ï¸ Model runs 100% locally

**Your ideas NEVER leave your machine.** Big Tech LLMs steal intellectual property - your business plans, code, innovations go directly to their servers and can be seen by competitors. With local inference, your ideas stay YOURS. Monitor network to verify zero data exfiltration.
## ğŸ”’ License

AGPL v3 + Commercial
- Free for open source
- Companies >$1M revenue need license

**Built by Silbaski Dejan**
